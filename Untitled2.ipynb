{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOedsmZZZEao/LeNwvEDt2u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hochuapelsinoviysok/parser/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests # подключение библиотек\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "bank_id = 3751162 # ID банка на сайте banki.ru\n",
        "\n",
        "url = 'https://www.banki.ru/services/questions-answers/?id=%d&p=1' % (bank_id) # url страницы\n",
        "r = requests.get(url)\n",
        "with open('banki.html', 'w') as output_file:\n",
        "  output_file.write(r.text) # сохраняем страницу в файл"
      ],
      "metadata": {
        "id": "S4NMx3m9SLL6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "bank_id = 1771062 #ID банка на сайте banki.ru\n",
        "page=1\n",
        "max_page=10\n",
        "\n",
        "url = 'https://www.banki.ru/services/questions-answers/?id=%d&p=%d' % (bank_id, page) # url страницы"
      ],
      "metadata": {
        "id": "jUoE0AJfSOnH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame()\n",
        "\n",
        "r = requests.get(url) #отправляем HTTP запрос и получаем результат\n",
        "soup = BeautifulSoup(r.text) #Отправляем полученную страницу в библиотеку для парсинга\n",
        "tables=soup.find_all('table', {'class': 'qaBlock'}) #Получаем все таблицы с вопросами\n",
        "for item in tables:\n",
        "    res=parse_table(item)"
      ],
      "metadata": {
        "id": "xuwektHrSSwY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_table(table):#Функция разбора таблицы с вопросом\n",
        "    res = pd.DataFrame()\n",
        "\n",
        "    id_question=0\n",
        "    link_question=''\n",
        "    date_question=''\n",
        "    question=''\n",
        "    who_asked=''\n",
        "    who_asked_id=''\n",
        "    who_asked_link=''\n",
        "    who_asked_city=''\n",
        "    answer=''\n",
        "    \n",
        "    question_tr=table.find('tr',{'class': 'question'})\n",
        "    #Получаем сам вопрос\n",
        "    question=question_tr.find_all('td')[1].find('div').text.replace('<br />','\\n').strip()\n",
        "    \n",
        "    widget_info=question_tr.find_all('div', {'class':'widget__info'})\n",
        "    #Получаем ссылку на сам вопрос\n",
        "    link_question='https://www.banki.ru'+widget_info[0].find('a').get('href').strip()\n",
        "    #Получаем уникальным номер вопроса\n",
        "    id_question=link_question.split('=')[1]\n",
        "\n",
        "    #Получаем того кто задал вопрос\n",
        "    who_asked=widget_info[1].find('a').text.strip()\n",
        "    #Получаем ссылку на профиль\n",
        "    who_asked_link='https://www.banki.ru'+widget_info[1].find('a').get('href').strip()\n",
        "    #Получаем уникальный номер профиля\n",
        "    who_asked_id=widget_info[1].find('a').get('href').strip().split('=')[1]\n",
        "\n",
        "    #Получаем из какого города вопрос\n",
        "    who_asked_city=widget_info[1].text.split('(')[1].split(')')[0].strip()\n",
        "    \n",
        "    #Получаем дату вопроса\n",
        "    date_question=widget_info[1].text.split('(')[1].split(')')[1].strip()\n",
        "    \n",
        "    #Получаем ответ если он есть сохраняем\n",
        "    answer_tr=table.find('tr',{'class': 'answer'})\n",
        "    if(answer_tr!=None):\n",
        "        answer=answer_tr.find_all('td')[1].find('div').text.replace('<br />','\\n').strip()\n",
        "    \n",
        "    #Пишем в таблицу и возвращаем\n",
        "    res=res.append(pd.DataFrame([[id_question,link_question,question,date_question,who_asked,who_asked_id,who_asked_link,who_asked_city,answer]], columns = ['id_question','link_question','question','date_question','who_asked','who_asked_id','who_asked_city','who_asked_link','answer']), ignore_index=True)\n",
        "    #print(res)\n",
        "    return(res)\n"
      ],
      "metadata": {
        "id": "fq4B7wp8SY6R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame()\n",
        "\n",
        "r = requests.get(url) #отправляем HTTP запрос и получаем результат\n",
        "soup = BeautifulSoup(r.text) #Отправляем полученную страницу в библиотеку для парсинга\n",
        "tables=soup.find_all('table', {'class': 'qaBlock'}) #Получаем все таблицы с вопросами\n",
        "for item in tables:\n",
        "    res=parse_table(item)\n",
        "    result=result.append(res, ignore_index=True)\n",
        "\n",
        "result.to_excel('result.xlsx')"
      ],
      "metadata": {
        "id": "qDjtuxz2Scx9"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}